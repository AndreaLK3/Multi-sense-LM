INFO : Data(edge_index=[2, 90328], edge_type=[90328], node_types=[71882], num_relations=[1], x=[71882, 300])
INFO : Graph-data object loaded, model initialized. Moving them to GPU device(s) if present.
INFO : Loading graphArea matrix, with area_size=32 from: Graph/nodes_32_graphArea_matrix.npy
INFO : 
Training epoch n.1:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=12	 ; Iteration time=0.01291
INFO : -----
 End of epoch. Global step n.16, using batch_size=8
INFO : Training, epoch nll_loss= 18.83654
------
INFO : 
Training epoch n.2:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=24	 ; Iteration time=0.01258
INFO : -----
 End of epoch. Global step n.32, using batch_size=8
INFO : Training, epoch nll_loss= 11.57502
------
INFO : 
Training epoch n.3:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=36	 ; Iteration time=0.01317
INFO : Global step=48	 ; Iteration time=0.01274
INFO : -----
 End of epoch. Global step n.48, using batch_size=8
INFO : Training, epoch nll_loss= 7.61745
------
INFO : 
Training epoch n.4:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=60	 ; Iteration time=0.01272
INFO : -----
 End of epoch. Global step n.64, using batch_size=8
INFO : Training, epoch nll_loss= 7.10932
------
INFO : 
Training epoch n.5:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=72	 ; Iteration time=0.0126
INFO : -----
 End of epoch. Global step n.80, using batch_size=8
INFO : Training, epoch nll_loss= 6.95478
------
INFO : 
Training epoch n.6:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=84	 ; Iteration time=0.01305
INFO : Global step=96	 ; Iteration time=0.01257
INFO : -----
 End of epoch. Global step n.96, using batch_size=8
INFO : Training, epoch nll_loss= 6.77831
------
INFO : 
Training epoch n.7:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=108	 ; Iteration time=0.0127
INFO : -----
 End of epoch. Global step n.112, using batch_size=8
INFO : Training, epoch nll_loss= 6.50495
------
INFO : 
Training epoch n.8:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=120	 ; Iteration time=0.0128
INFO : -----
 End of epoch. Global step n.128, using batch_size=8
INFO : Training, epoch nll_loss= 6.22941
------
INFO : 
Training epoch n.9:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=132	 ; Iteration time=0.01289
INFO : Global step=144	 ; Iteration time=0.0127
INFO : -----
 End of epoch. Global step n.144, using batch_size=8
INFO : Training, epoch nll_loss= 5.98392
------
INFO : 
Training epoch n.10:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=156	 ; Iteration time=0.01271
INFO : -----
 End of epoch. Global step n.160, using batch_size=8
INFO : Training, epoch nll_loss= 5.77052
------
INFO : 
Training epoch n.11:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=168	 ; Iteration time=0.01258
INFO : -----
 End of epoch. Global step n.176, using batch_size=8
INFO : Training, epoch nll_loss= 5.57284
------
INFO : 
Training epoch n.12:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=180	 ; Iteration time=0.01276
INFO : Global step=192	 ; Iteration time=0.01274
INFO : -----
 End of epoch. Global step n.192, using batch_size=8
INFO : Training, epoch nll_loss= 5.38293
------
INFO : 
Training epoch n.13:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=204	 ; Iteration time=0.0129
INFO : -----
 End of epoch. Global step n.208, using batch_size=8
INFO : Training, epoch nll_loss= 5.20347
------
INFO : 
Training epoch n.14:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=216	 ; Iteration time=0.01273
INFO : -----
 End of epoch. Global step n.224, using batch_size=8
INFO : Training, epoch nll_loss= 5.04101
------
INFO : 
Training epoch n.15:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=228	 ; Iteration time=0.0128
INFO : Global step=240	 ; Iteration time=0.01253
INFO : -----
 End of epoch. Global step n.240, using batch_size=8
INFO : Training, epoch nll_loss= 4.89664
------
INFO : 
Training epoch n.16:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=252	 ; Iteration time=0.01277
INFO : -----
 End of epoch. Global step n.256, using batch_size=8
INFO : Training, epoch nll_loss= 4.74994
------
INFO : 
Training epoch n.17:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=264	 ; Iteration time=0.0129
INFO : -----
 End of epoch. Global step n.272, using batch_size=8
INFO : Training, epoch nll_loss= 4.62057
------
INFO : 
Training epoch n.18:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=276	 ; Iteration time=0.01306
INFO : Global step=288	 ; Iteration time=0.01278
INFO : -----
 End of epoch. Global step n.288, using batch_size=8
INFO : Training, epoch nll_loss= 4.5064
------
INFO : 
Training epoch n.19:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=300	 ; Iteration time=0.01294
INFO : -----
 End of epoch. Global step n.304, using batch_size=8
INFO : Training, epoch nll_loss= 4.40696
------
INFO : 
Training epoch n.20:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=312	 ; Iteration time=0.0129
INFO : -----
 End of epoch. Global step n.320, using batch_size=8
INFO : Training, epoch nll_loss= 4.29726
------
INFO : 
Training epoch n.21:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=324	 ; Iteration time=0.01283
INFO : Global step=336	 ; Iteration time=0.01255
INFO : -----
 End of epoch. Global step n.336, using batch_size=8
INFO : Training, epoch nll_loss= 4.21151
------
INFO : 
Training epoch n.22:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=348	 ; Iteration time=0.01287
INFO : -----
 End of epoch. Global step n.352, using batch_size=8
INFO : Training, epoch nll_loss= 4.13
------
INFO : 
Training epoch n.23:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=360	 ; Iteration time=0.01261
INFO : -----
 End of epoch. Global step n.368, using batch_size=8
INFO : Training, epoch nll_loss= 4.05079
------
INFO : 
Training epoch n.24:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=372	 ; Iteration time=0.01369
INFO : Global step=384	 ; Iteration time=0.01268
INFO : -----
 End of epoch. Global step n.384, using batch_size=8
INFO : Training, epoch nll_loss= 3.97794
------
INFO : 
Training epoch n.25:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=396	 ; Iteration time=0.01285
INFO : -----
 End of epoch. Global step n.400, using batch_size=8
INFO : Training, epoch nll_loss= 3.91492
------
INFO : 
Training epoch n.26:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=408	 ; Iteration time=0.01259
INFO : -----
 End of epoch. Global step n.416, using batch_size=8
INFO : Training, epoch nll_loss= 3.84319
------
INFO : 
Training epoch n.27:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=420	 ; Iteration time=0.01347
INFO : Global step=432	 ; Iteration time=0.01281
INFO : -----
 End of epoch. Global step n.432, using batch_size=8
INFO : Training, epoch nll_loss= 3.78144
------
INFO : 
Training epoch n.28:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=444	 ; Iteration time=0.01292
INFO : -----
 End of epoch. Global step n.448, using batch_size=8
INFO : Training, epoch nll_loss= 3.71903
------
INFO : 
Training epoch n.29:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=456	 ; Iteration time=0.01261
INFO : -----
 End of epoch. Global step n.464, using batch_size=8
INFO : Training, epoch nll_loss= 3.65999
------
INFO : 
Training epoch n.30:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=468	 ; Iteration time=0.01297
INFO : Global step=480	 ; Iteration time=0.01258
INFO : -----
 End of epoch. Global step n.480, using batch_size=8
INFO : Training, epoch nll_loss= 3.60732
------
INFO : 
Training epoch n.31:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=492	 ; Iteration time=0.01279
INFO : -----
 End of epoch. Global step n.496, using batch_size=8
INFO : Training, epoch nll_loss= 3.55306
------
INFO : 
Training epoch n.32:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=504	 ; Iteration time=0.01265
INFO : -----
 End of epoch. Global step n.512, using batch_size=8
INFO : Training, epoch nll_loss= 3.50268
------
INFO : 
Training epoch n.33:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=516	 ; Iteration time=0.01279
INFO : Global step=528	 ; Iteration time=0.0126
INFO : -----
 End of epoch. Global step n.528, using batch_size=8
INFO : Training, epoch nll_loss= 3.44919
------
INFO : 
Training epoch n.34:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=540	 ; Iteration time=0.01276
INFO : -----
 End of epoch. Global step n.544, using batch_size=8
INFO : Training, epoch nll_loss= 3.3958
------
INFO : 
Training epoch n.35:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=552	 ; Iteration time=0.0127
INFO : -----
 End of epoch. Global step n.560, using batch_size=8
INFO : Training, epoch nll_loss= 3.39958
------
INFO : 
Training epoch n.36:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=564	 ; Iteration time=0.01278
INFO : Global step=576	 ; Iteration time=0.01276
INFO : -----
 End of epoch. Global step n.576, using batch_size=8
INFO : Training, epoch nll_loss= 3.31067
------
INFO : 
Training epoch n.37:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=588	 ; Iteration time=0.01282
INFO : -----
 End of epoch. Global step n.592, using batch_size=8
INFO : Training, epoch nll_loss= 3.3348
------
INFO : 
Training epoch n.38:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=600	 ; Iteration time=0.01263
INFO : -----
 End of epoch. Global step n.608, using batch_size=8
INFO : Training, epoch nll_loss= 3.22831
------
INFO : 
Training epoch n.39:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=612	 ; Iteration time=0.01291
INFO : Global step=624	 ; Iteration time=0.01257
INFO : -----
 End of epoch. Global step n.624, using batch_size=8
INFO : Training, epoch nll_loss= 3.18394
------
INFO : 
Training epoch n.40:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=636	 ; Iteration time=0.01271
INFO : -----
 End of epoch. Global step n.640, using batch_size=8
INFO : Training, epoch nll_loss= 3.14713
------
INFO : 
Training epoch n.41:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=648	 ; Iteration time=0.01263
INFO : -----
 End of epoch. Global step n.656, using batch_size=8
INFO : Training, epoch nll_loss= 3.11361
------
INFO : 
Training epoch n.42:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=660	 ; Iteration time=0.0128
INFO : Global step=672	 ; Iteration time=0.01295
INFO : -----
 End of epoch. Global step n.672, using batch_size=8
INFO : Training, epoch nll_loss= 3.07072
------
INFO : 
Training epoch n.43:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=684	 ; Iteration time=0.01271
INFO : -----
 End of epoch. Global step n.688, using batch_size=8
INFO : Training, epoch nll_loss= 3.03366
------
INFO : 
Training epoch n.44:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=696	 ; Iteration time=0.01301
INFO : -----
 End of epoch. Global step n.704, using batch_size=8
INFO : Training, epoch nll_loss= 3.00234
------
INFO : 
Training epoch n.45:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=708	 ; Iteration time=0.01323
INFO : Global step=720	 ; Iteration time=0.01261
INFO : -----
 End of epoch. Global step n.720, using batch_size=8
INFO : Training, epoch nll_loss= 2.9613
------
INFO : 
Training epoch n.46:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=732	 ; Iteration time=0.01282
INFO : -----
 End of epoch. Global step n.736, using batch_size=8
INFO : Training, epoch nll_loss= 2.93264
------
INFO : 
Training epoch n.47:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=744	 ; Iteration time=0.01259
INFO : -----
 End of epoch. Global step n.752, using batch_size=8
INFO : Training, epoch nll_loss= 2.90081
------
INFO : 
Training epoch n.48:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=756	 ; Iteration time=0.01309
INFO : Global step=768	 ; Iteration time=0.01259
INFO : -----
 End of epoch. Global step n.768, using batch_size=8
INFO : Training, epoch nll_loss= 2.87178
------
INFO : 
Training epoch n.49:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=780	 ; Iteration time=0.0127
INFO : -----
 End of epoch. Global step n.784, using batch_size=8
INFO : Training, epoch nll_loss= 2.83893
------
INFO : 
Training epoch n.50:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=792	 ; Iteration time=0.01266
INFO : -----
 End of epoch. Global step n.800, using batch_size=8
INFO : Training, epoch nll_loss= 2.81056
------
INFO : 
Training epoch n.51:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=804	 ; Iteration time=0.01297
INFO : Global step=816	 ; Iteration time=0.01265
INFO : -----
 End of epoch. Global step n.816, using batch_size=8
INFO : Training, epoch nll_loss= 2.78665
------
INFO : 
Training epoch n.52:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=828	 ; Iteration time=0.01293
INFO : -----
 End of epoch. Global step n.832, using batch_size=8
INFO : Training, epoch nll_loss= 2.75744
------
INFO : 
Training epoch n.53:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=840	 ; Iteration time=0.01261
INFO : -----
 End of epoch. Global step n.848, using batch_size=8
INFO : Training, epoch nll_loss= 2.73287
------
INFO : 
Training epoch n.54:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=852	 ; Iteration time=0.01304
INFO : Global step=864	 ; Iteration time=0.01266
INFO : -----
 End of epoch. Global step n.864, using batch_size=8
INFO : Training, epoch nll_loss= 2.70896
------
INFO : 
Training epoch n.55:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=876	 ; Iteration time=0.01285
INFO : -----
 End of epoch. Global step n.880, using batch_size=8
INFO : Training, epoch nll_loss= 2.6817
------
INFO : 
Training epoch n.56:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=888	 ; Iteration time=0.01264
INFO : -----
 End of epoch. Global step n.896, using batch_size=8
INFO : Training, epoch nll_loss= 2.66012
------
INFO : 
Training epoch n.57:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=900	 ; Iteration time=0.01306
INFO : Global step=912	 ; Iteration time=0.01285
INFO : -----
 End of epoch. Global step n.912, using batch_size=8
INFO : Training, epoch nll_loss= 2.63057
------
INFO : 
Training epoch n.58:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=924	 ; Iteration time=0.01268
INFO : -----
 End of epoch. Global step n.928, using batch_size=8
INFO : Training, epoch nll_loss= 2.61948
------
INFO : 
Training epoch n.59:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=936	 ; Iteration time=0.01262
INFO : -----
 End of epoch. Global step n.944, using batch_size=8
INFO : Training, epoch nll_loss= 2.59431
------
INFO : 
Training epoch n.60:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=948	 ; Iteration time=0.01311
INFO : Global step=960	 ; Iteration time=0.01265
INFO : -----
 End of epoch. Global step n.960, using batch_size=8
INFO : Training, epoch nll_loss= 2.57426
------
INFO : 
Training epoch n.61:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=972	 ; Iteration time=0.01282
INFO : -----
 End of epoch. Global step n.976, using batch_size=8
INFO : Training, epoch nll_loss= 2.55272
------
INFO : 
Training epoch n.62:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=984	 ; Iteration time=0.01258
INFO : -----
 End of epoch. Global step n.992, using batch_size=8
INFO : Training, epoch nll_loss= 2.5369
------
INFO : 
Training epoch n.63:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=996	 ; Iteration time=0.01297
INFO : Global step=1008	 ; Iteration time=0.01259
INFO : -----
 End of epoch. Global step n.1008, using batch_size=8
INFO : Training, epoch nll_loss= 2.51754
------
INFO : 
Training epoch n.64:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1020	 ; Iteration time=0.01269
INFO : -----
 End of epoch. Global step n.1024, using batch_size=8
INFO : Training, epoch nll_loss= 2.49812
------
INFO : 
Training epoch n.65:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1032	 ; Iteration time=0.01259
INFO : -----
 End of epoch. Global step n.1040, using batch_size=8
INFO : Training, epoch nll_loss= 2.48078
------
INFO : 
Training epoch n.66:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1044	 ; Iteration time=0.01302
INFO : Global step=1056	 ; Iteration time=0.01263
INFO : -----
 End of epoch. Global step n.1056, using batch_size=8
INFO : Training, epoch nll_loss= 2.47018
------
INFO : 
Training epoch n.67:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1068	 ; Iteration time=0.01288
INFO : -----
 End of epoch. Global step n.1072, using batch_size=8
INFO : Training, epoch nll_loss= 2.45236
------
INFO : 
Training epoch n.68:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1080	 ; Iteration time=0.01285
INFO : -----
 End of epoch. Global step n.1088, using batch_size=8
INFO : Training, epoch nll_loss= 2.43956
------
INFO : 
Training epoch n.69:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1092	 ; Iteration time=0.01288
INFO : Global step=1104	 ; Iteration time=0.01269
INFO : -----
 End of epoch. Global step n.1104, using batch_size=8
INFO : Training, epoch nll_loss= 2.42236
------
INFO : 
Training epoch n.70:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1116	 ; Iteration time=0.01272
INFO : -----
 End of epoch. Global step n.1120, using batch_size=8
INFO : Training, epoch nll_loss= 2.40992
------
INFO : 
Training epoch n.71:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1128	 ; Iteration time=0.01267
INFO : -----
 End of epoch. Global step n.1136, using batch_size=8
INFO : Training, epoch nll_loss= 2.39957
------
INFO : 
Training epoch n.72:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1140	 ; Iteration time=0.01278
INFO : Global step=1152	 ; Iteration time=0.01338
INFO : -----
 End of epoch. Global step n.1152, using batch_size=8
INFO : Training, epoch nll_loss= 2.38545
------
INFO : 
Training epoch n.73:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1164	 ; Iteration time=0.01286
INFO : -----
 End of epoch. Global step n.1168, using batch_size=8
INFO : Training, epoch nll_loss= 2.37452
------
INFO : 
Training epoch n.74:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1176	 ; Iteration time=0.01261
INFO : -----
 End of epoch. Global step n.1184, using batch_size=8
INFO : Training, epoch nll_loss= 2.36612
------
INFO : 
Training epoch n.75:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1188	 ; Iteration time=0.01311
INFO : Global step=1200	 ; Iteration time=0.01299
INFO : -----
 End of epoch. Global step n.1200, using batch_size=8
INFO : Training, epoch nll_loss= 2.35077
------
INFO : 
Training epoch n.76:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1212	 ; Iteration time=0.01274
INFO : -----
 End of epoch. Global step n.1216, using batch_size=8
INFO : Training, epoch nll_loss= 2.34688
------
INFO : 
Training epoch n.77:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1224	 ; Iteration time=0.01271
INFO : -----
 End of epoch. Global step n.1232, using batch_size=8
INFO : Training, epoch nll_loss= 2.3297
------
INFO : 
Training epoch n.78:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1236	 ; Iteration time=0.01301
INFO : Global step=1248	 ; Iteration time=0.01257
INFO : -----
 End of epoch. Global step n.1248, using batch_size=8
INFO : Training, epoch nll_loss= 2.32926
------
INFO : 
Training epoch n.79:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1260	 ; Iteration time=0.01269
INFO : -----
 End of epoch. Global step n.1264, using batch_size=8
INFO : Training, epoch nll_loss= 2.31231
------
INFO : 
Training epoch n.80:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1272	 ; Iteration time=0.01264
INFO : -----
 End of epoch. Global step n.1280, using batch_size=8
INFO : Training, epoch nll_loss= 2.31192
------
INFO : 
Training epoch n.81:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1284	 ; Iteration time=0.01279
INFO : Global step=1296	 ; Iteration time=0.01268
INFO : -----
 End of epoch. Global step n.1296, using batch_size=8
INFO : Training, epoch nll_loss= 2.30529
------
INFO : 
Training epoch n.82:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1308	 ; Iteration time=0.01282
INFO : -----
 End of epoch. Global step n.1312, using batch_size=8
INFO : Training, epoch nll_loss= 2.29739
------
INFO : 
Training epoch n.83:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1320	 ; Iteration time=0.013
INFO : -----
 End of epoch. Global step n.1328, using batch_size=8
INFO : Training, epoch nll_loss= 2.28716
------
INFO : 
Training epoch n.84:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1332	 ; Iteration time=0.01295
INFO : Global step=1344	 ; Iteration time=0.01255
INFO : -----
 End of epoch. Global step n.1344, using batch_size=8
INFO : Training, epoch nll_loss= 2.2829
------
INFO : 
Training epoch n.85:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1356	 ; Iteration time=0.01284
INFO : -----
 End of epoch. Global step n.1360, using batch_size=8
INFO : Training, epoch nll_loss= 2.26548
------
INFO : 
Training epoch n.86:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1368	 ; Iteration time=0.01264
INFO : -----
 End of epoch. Global step n.1376, using batch_size=8
INFO : Training, epoch nll_loss= 2.27603
------
INFO : 
Training epoch n.87:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1380	 ; Iteration time=0.01322
INFO : Global step=1392	 ; Iteration time=0.01264
INFO : -----
 End of epoch. Global step n.1392, using batch_size=8
INFO : Training, epoch nll_loss= 2.25579
------
INFO : 
Training epoch n.88:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1404	 ; Iteration time=0.01272
INFO : -----
 End of epoch. Global step n.1408, using batch_size=8
INFO : Training, epoch nll_loss= 2.25742
------
INFO : 
Training epoch n.89:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1416	 ; Iteration time=0.0126
INFO : -----
 End of epoch. Global step n.1424, using batch_size=8
INFO : Training, epoch nll_loss= 2.25551
------
INFO : 
Training epoch n.90:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1428	 ; Iteration time=0.01301
INFO : Global step=1440	 ; Iteration time=0.0131
INFO : -----
 End of epoch. Global step n.1440, using batch_size=8
INFO : Training, epoch nll_loss= 2.24615
------
INFO : 
Training epoch n.91:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1452	 ; Iteration time=0.01272
INFO : -----
 End of epoch. Global step n.1456, using batch_size=8
INFO : Training, epoch nll_loss= 2.24355
------
INFO : 
Training epoch n.92:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1464	 ; Iteration time=0.01262
INFO : -----
 End of epoch. Global step n.1472, using batch_size=8
INFO : Training, epoch nll_loss= 2.23518
------
INFO : 
Training epoch n.93:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1476	 ; Iteration time=0.01311
INFO : Global step=1488	 ; Iteration time=0.01295
INFO : -----
 End of epoch. Global step n.1488, using batch_size=8
INFO : Training, epoch nll_loss= 2.24087
------
INFO : 
Training epoch n.94:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1500	 ; Iteration time=0.01269
INFO : -----
 End of epoch. Global step n.1504, using batch_size=8
INFO : Training, epoch nll_loss= 2.23125
------
INFO : 
Training epoch n.95:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1512	 ; Iteration time=0.0126
INFO : -----
 End of epoch. Global step n.1520, using batch_size=8
INFO : Training, epoch nll_loss= 2.22161
------
INFO : 
Training epoch n.96:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1524	 ; Iteration time=0.01302
INFO : Global step=1536	 ; Iteration time=0.01262
INFO : -----
 End of epoch. Global step n.1536, using batch_size=8
INFO : Training, epoch nll_loss= 2.21889
------
INFO : 
Training epoch n.97:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1548	 ; Iteration time=0.01282
INFO : -----
 End of epoch. Global step n.1552, using batch_size=8
INFO : Training, epoch nll_loss= 2.20666
------
INFO : 
Training epoch n.98:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1560	 ; Iteration time=0.0126
INFO : -----
 End of epoch. Global step n.1568, using batch_size=8
INFO : Training, epoch nll_loss= 2.21707
------
INFO : 
Training epoch n.99:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Global step=1572	 ; Iteration time=0.01289
INFO : Global step=1584	 ; Iteration time=0.01262
INFO : -----
 End of epoch. Global step n.1584, using batch_size=8
INFO : Training, epoch nll_loss= 2.19006
------
INFO : 
Training epoch n.100:
INFO : Preliminary: reading the dataset to determine the number of samples
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : Generator over subcorpus at TextCorpuses/ufsac-public-2.1/Training/semcor.xml
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: group.n.01
INFO : tensor([ 689, 8741,   15,  ..., 6334, 4835, 1469], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: September ; probability = 36.65%
INFO : Word: jury ; probability = 33.98%
INFO : Word: <unk> ; probability = 28.31%
INFO : Word: been ; probability = 0.65%
INFO : Word: was ; probability = 0.18%
INFO : tensor([ 9470,  8080,   751,  ...,   294,  6730, 16638], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: jury.n.01 ; probability = 56.69%
INFO : Sense: group.n.01 ; probability = 43.13%
INFO : Sense: appoint.v.02 ; probability = 0.07%
INFO : Sense: state.v.01 ; probability = 0.02%
INFO : Sense: person.n.01 ; probability = 0.02%
INFO : 
-----
Label: the next global is: said
INFO : Label: the next sense is: state.v.01
INFO : tensor([   58,   656,    15,  ...,  8656, 12446,  3105], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: , ; probability = 38.93%
INFO : Word: said ; probability = 38.03%
INFO : Word: <unk> ; probability = 11.38%
INFO : Word: and ; probability = 3.21%
INFO : Word: which ; probability = 3.2%
INFO : tensor([16309, 13109,  6705,  ..., 11837,  2193,  5162], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: state.v.01 ; probability = 95.58%
INFO : Sense: produce.v.04 ; probability = 2.17%
INFO : Sense: far.r.02 ; probability = 0.7%
INFO : Sense: person.n.01 ; probability = 0.46%
INFO : Sense: mission.n.03 ; probability = 0.38%
INFO : 
-----
Label: the next global is: Friday
INFO : Label: the next sense is: None
INFO : tensor([   58,    60, 11525,  ...,  1683,  4203,   569], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: , ; probability = 41.48%
INFO : Word: in ; probability = 33.9%
INFO : Word: Friday ; probability = 23.78%
INFO : Word: . ; probability = 0.37%
INFO : Word: was ; probability = 0.26%
INFO : 
-----
Label: the next global is: an
INFO : Label: the next sense is: None
INFO : tensor([ 129, 1608,  285,  ..., 1182, 3628, 7536], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: an ; probability = 100.0%
INFO : Word: s ; probability = 0.0%
INFO : Word: which ; probability = 0.0%
INFO : Word: <unk> ; probability = 0.0%
INFO : Word: investigate ; probability = 0.0%
INFO : 
-----
Label: the next global is: investigation
INFO : Label: the next sense is: probe.n.01
INFO : tensor([ 2536,    65,    16,  ...,  4586, 11467,   869], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: investigation ; probability = 97.0%
INFO : Word: of ; probability = 2.18%
INFO : Word: by ; probability = 0.34%
INFO : Word: was ; probability = 0.19%
INFO : Word: <unk> ; probability = 0.16%
INFO : tensor([13084, 10875,  9470,  ...,  9077,  9938, 13632], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: probe.n.01 ; probability = 98.99%
INFO : Sense: mission.n.03 ; probability = 0.61%
INFO : Sense: jury.n.01 ; probability = 0.17%
INFO : Sense: relative.a.01 ; probability = 0.06%
INFO : Sense: state.v.01 ; probability = 0.05%
INFO : 
-----
Label: the next global is: of
INFO : Label: the next sense is: None
INFO : tensor([   15,    65,     5,  ...,  2362, 13212,  8170], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 32.29%
INFO : Word: of ; probability = 31.81%
INFO : Word: the ; probability = 11.58%
INFO : Word: said ; probability = 7.53%
INFO : Word: in ; probability = 5.38%
INFO : 
-----
Label: the next global is: Atlanta
INFO : Label: the next sense is: None
INFO : tensor([    5,   846,    78,  ..., 11741,  8257,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 35.87%
INFO : Word: possible ; probability = 17.19%
INFO : Word: such ; probability = 16.8%
INFO : Word: voters ; probability = 14.04%
INFO : Word: Atlanta ; probability = 12.82%
INFO : 
-----
Label: the next global is: s
INFO : Label: the next sense is: None
INFO : tensor([1608,   65,   97,  ..., 1447, 7127, 7447], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: s ; probability = 99.93%
INFO : Word: of ; probability = 0.06%
INFO : Word: was ; probability = 0.0%
INFO : Word: <unk> ; probability = 0.0%
INFO : Word: an ; probability = 0.0%
INFO : 
-----
Label: the next global is: recent
INFO : Label: the next sense is: late.s.03
INFO : tensor([ 4835,    25,    58,  ...,  2115,  2180, 13433], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: recent ; probability = 92.28%
INFO : Word: . ; probability = 2.38%
INFO : Word: , ; probability = 1.31%
INFO : Word: term ; probability = 1.12%
INFO : Word: <unk> ; probability = 0.94%
INFO : tensor([ 9704, 17217, 11902,  ...,  3456,  5162,  1680], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: late.s.03 ; probability = 96.5%
INFO : Sense: term.n.02 ; probability = 1.79%
INFO : Sense: overall.s.02 ; probability = 0.42%
INFO : Sense: jury.n.01 ; probability = 0.33%
INFO : Sense: end.n.02 ; probability = 0.33%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: primary.n.01
INFO : tensor([   15,  2246,    60,  ..., 12263,    41,  1469], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 99.99%
INFO : Word: reports ; probability = 0.01%
INFO : Word: in ; probability = 0.0%
INFO : Word: a ; probability = 0.0%
INFO : Word: September ; probability = 0.0%
INFO : tensor([13019,  9470, 14129,  ...,  3329, 16624, 17870], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: primary.n.01 ; probability = 99.98%
INFO : Sense: jury.n.01 ; probability = 0.01%
INFO : Sense: report.n.03 ; probability = 0.01%
INFO : Sense: end.n.02 ; probability = 0.0%
INFO : Sense: state.v.01 ; probability = 0.0%
INFO : 
-----
Label: the next global is: produced
INFO : Label: the next sense is: produce.v.04
INFO : tensor([ 285,  548,   58,  ..., 6661, 5397, 5481], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: which ; probability = 44.2%
INFO : Word: produced ; probability = 40.69%
INFO : Word: , ; probability = 5.12%
INFO : Word: <unk> ; probability = 2.47%
INFO : Word: said ; probability = 2.27%
INFO : tensor([13109, 16309,  6705,  ...,  5162,   325,  2193], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: produce.v.04 ; probability = 94.99%
INFO : Sense: state.v.01 ; probability = 4.2%
INFO : Sense: far.r.02 ; probability = 0.4%
INFO : Sense: term.n.02 ; probability = 0.24%
INFO : Sense: person.n.01 ; probability = 0.05%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([  15,   97,    5,  ..., 2483, 2180, 5474], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 79.9%
INFO : Word: was ; probability = 5.18%
INFO : Word: the ; probability = 2.58%
INFO : Word: of ; probability = 2.48%
INFO : Word: by ; probability = 2.1%
INFO : 
-----
Label: the next global is: no
INFO : Label: the next sense is: None
INFO : tensor([   15,   348,   128,  ..., 11029,  1023,   430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 21.16%
INFO : Word: The ; probability = 10.93%
INFO : Word: that ; probability = 9.87%
INFO : Word: primary ; probability = 6.34%
INFO : Word: in ; probability = 6.29%
INFO : 
-----
Label: the next global is: evidence
INFO : Label: the next sense is: evidence.n.01
INFO : tensor([    5,    15,  1023,  ..., 11741,  7536,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 34.81%
INFO : Word: <unk> ; probability = 23.1%
INFO : Word: handful ; probability = 15.71%
INFO : Word: which ; probability = 13.39%
INFO : Word: evidence ; probability = 11.14%
INFO : tensor([ 8201,  6276, 12835,  ...,  7088,  5070,  1387], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: handful.n.01 ; probability = 57.37%
INFO : Sense: evidence.n.01 ; probability = 40.85%
INFO : Sense: potential.a.01 ; probability = 0.75%
INFO : Sense: such.s.01 ; probability = 0.75%
INFO : Sense: conduct.v.01 ; probability = 0.09%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([   15,    65,   656,  ...,  8170, 10983, 10452], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 54.73%
INFO : Word: of ; probability = 20.16%
INFO : Word: said ; probability = 17.41%
INFO : Word: the ; probability = 2.21%
INFO : Word: in ; probability = 1.68%
INFO : 
-----
Label: the next global is: that
INFO : Label: the next sense is: None
INFO : tensor([   15,   348,   128,  ..., 11029,  1023,   430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 21.16%
INFO : Word: The ; probability = 10.93%
INFO : Word: that ; probability = 9.87%
INFO : Word: primary ; probability = 6.34%
INFO : Word: in ; probability = 6.29%
INFO : 
-----
Label: the next global is: any
INFO : Label: the next sense is: None
INFO : tensor([    5,  1063,   385,  ...,  7547, 10682,  7587], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 78.78%
INFO : Word: any ; probability = 21.0%
INFO : Word: had ; probability = 0.11%
INFO : Word: said ; probability = 0.05%
INFO : Word: of ; probability = 0.02%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([   15,    65,  8741,  ...,  3105,   869, 12446], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 81.14%
INFO : Word: of ; probability = 7.14%
INFO : Word: jury ; probability = 3.93%
INFO : Word: was ; probability = 2.04%
INFO : Word: the ; probability = 1.32%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: happen.v.01
INFO : tensor([   15,   348,   128,  ..., 11029,  1023,   430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 19.75%
INFO : Word: The ; probability = 10.68%
INFO : Word: that ; probability = 10.31%
INFO : Word: primary ; probability = 6.39%
INFO : Word: in ; probability = 6.32%
INFO : tensor([13019,  3056, 10720,  ...,  1134,  8201,  6276], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: primary.n.01 ; probability = 26.69%
INFO : Sense: city.n.01 ; probability = 25.58%
INFO : Sense: merely.r.01 ; probability = 19.05%
INFO : Sense: happen.v.01 ; probability = 14.83%
INFO : Sense: consider.v.04 ; probability = 13.2%
INFO : 
-----
Label: the next global is: .
INFO : Label: the next sense is: None
INFO : tensor([  25,    5,  656,  ..., 2180, 4203,  569], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: . ; probability = 79.69%
INFO : Word: the ; probability = 9.91%
INFO : Word: said ; probability = 3.33%
INFO : Word: in ; probability = 2.84%
INFO : Word: <unk> ; probability = 1.45%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([  15,  131, 1683,  ..., 1397, 7536, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 99.8%
INFO : Word: received ; probability = 0.05%
INFO : Word: won ; probability = 0.05%
INFO : Word: conducted ; probability = 0.04%
INFO : Word: had ; probability = 0.02%
INFO : 
-----
Label: the next global is: The
INFO : Label: the next sense is: None
INFO : tensor([   15,   348,   128,  ..., 11029,  1023,   430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 19.75%
INFO : Word: The ; probability = 10.68%
INFO : Word: that ; probability = 10.31%
INFO : Word: primary ; probability = 6.39%
INFO : Word: in ; probability = 6.32%
INFO : 
-----
Label: the next global is: jury
INFO : Label: the next sense is: jury.n.01
INFO : tensor([ 689, 8741,   15,  ..., 6334, 4835, 1469], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: September ; probability = 37.73%
INFO : Word: jury ; probability = 31.24%
INFO : Word: <unk> ; probability = 29.67%
INFO : Word: been ; probability = 0.81%
INFO : Word: was ; probability = 0.23%
INFO : tensor([ 8080,  9470,   751,  ...,   294,  6730, 16638], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: group.n.01 ; probability = 54.04%
INFO : Sense: jury.n.01 ; probability = 45.75%
INFO : Sense: appoint.v.02 ; probability = 0.08%
INFO : Sense: state.v.01 ; probability = 0.03%
INFO : Sense: person.n.01 ; probability = 0.03%
INFO : 
-----
Label: the next global is: further
INFO : Label: the next sense is: far.r.02
INFO : tensor([  656,   385,  1276,  ..., 10983,  8170,  9467], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: said ; probability = 34.39%
INFO : Word: had ; probability = 29.1%
INFO : Word: further ; probability = 24.51%
INFO : Word: which ; probability = 1.81%
INFO : Word: <unk> ; probability = 1.79%
INFO : tensor([16309,  6705, 12275,  ...,  2841,  2788, 15092], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: state.v.01 ; probability = 47.99%
INFO : Sense: far.r.02 ; probability = 46.46%
INFO : Sense: person.n.01 ; probability = 1.49%
INFO : Sense: mission.n.03 ; probability = 1.05%
INFO : Sense: appoint.v.02 ; probability = 0.6%
INFO : 
-----
Label: the next global is: said
INFO : Label: the next sense is: state.v.01
INFO : tensor([  656,     5,  2246,  ...,  7863,  2541, 10452], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: said ; probability = 82.85%
INFO : Word: the ; probability = 4.88%
INFO : Word: reports ; probability = 2.65%
INFO : Word: . ; probability = 2.58%
INFO : Word: <unk> ; probability = 2.54%
INFO : tensor([16309, 14129, 10875,  ..., 17140,   633,  7025], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: state.v.01 ; probability = 96.11%
INFO : Sense: report.n.03 ; probability = 2.53%
INFO : Sense: mission.n.03 ; probability = 0.58%
INFO : Sense: jury.n.01 ; probability = 0.58%
INFO : Sense: end.n.02 ; probability = 0.14%
INFO : 
-----
Label: the next global is: in
INFO : Label: the next sense is: None
INFO : tensor([11525,    58,    60,  ...,  1683,  4203,   569], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: Friday ; probability = 38.58%
INFO : Word: , ; probability = 36.92%
INFO : Word: in ; probability = 23.47%
INFO : Word: . ; probability = 0.44%
INFO : Word: was ; probability = 0.33%
INFO : 
-----
Label: the next global is: term
INFO : Label: the next sense is: term.n.02
INFO : tensor([   5,  285, 2280,  ..., 4203,  569, 5474], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 82.62%
INFO : Word: which ; probability = 10.07%
INFO : Word: term ; probability = 7.24%
INFO : Word: by ; probability = 0.02%
INFO : Word: <unk> ; probability = 0.01%
INFO : tensor([17217, 11902,  6038,  ..., 18728,   751, 11504], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: term.n.02 ; probability = 100.0%
INFO : Sense: overall.s.02 ; probability = 0.0%
INFO : Sense: end.n.02 ; probability = 0.0%
INFO : Sense: late.s.03 ; probability = 0.0%
INFO : Sense: state.v.01 ; probability = 0.0%
INFO : 
-----
Label: the next global is: end
INFO : Label: the next sense is: end.n.02
INFO : tensor([ 8741,   487,    15,  ...,  2180,  2483, 13433], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: jury ; probability = 52.87%
INFO : Word: end ; probability = 35.75%
INFO : Word: <unk> ; probability = 4.53%
INFO : Word: the ; probability = 2.5%
INFO : Word: was ; probability = 1.55%
INFO : tensor([ 9470,  6038, 10875,  ..., 15122, 16624, 11068], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: jury.n.01 ; probability = 58.6%
INFO : Sense: end.n.02 ; probability = 39.43%
INFO : Sense: mission.n.03 ; probability = 1.51%
INFO : Sense: late.s.03 ; probability = 0.17%
INFO : Sense: overall.s.02 ; probability = 0.08%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([  15,   97,   60,  ..., 6716, 2115,  569], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 80.16%
INFO : Word: was ; probability = 11.66%
INFO : Word: in ; probability = 3.05%
INFO : Word: , ; probability = 3.01%
INFO : Word: the ; probability = 1.11%
INFO : 
-----
Label: the next global is: that
INFO : Label: the next sense is: None
INFO : tensor([   15,   348,   128,  ..., 11029,  1023,   430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 19.88%
INFO : Word: The ; probability = 10.88%
INFO : Word: that ; probability = 10.33%
INFO : Word: primary ; probability = 6.29%
INFO : Word: considering ; probability = 6.13%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([    5,  1063,   385,  ...,  7547, 10682,  7587], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 70.41%
INFO : Word: any ; probability = 29.35%
INFO : Word: had ; probability = 0.11%
INFO : Word: said ; probability = 0.05%
INFO : Word: of ; probability = 0.03%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: group.n.01
INFO : tensor([5601,   15, 4203,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: election ; probability = 24.9%
INFO : Word: <unk> ; probability = 22.4%
INFO : Word: widespread ; probability = 9.16%
INFO : Word: number ; probability = 8.9%
INFO : Word: size ; probability = 8.6%
INFO : tensor([ 5926, 15632, 10163,  ..., 17217, 11902,  9704], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: election.n.01 ; probability = 25.91%
INFO : Sense: size.n.01 ; probability = 12.23%
INFO : Sense: location.n.01 ; probability = 12.18%
INFO : Sense: praise.n.01 ; probability = 11.78%
INFO : Sense: manner.n.01 ; probability = 11.61%
INFO : 
-----
Label: the next global is: ,
INFO : Label: the next sense is: None
INFO : tensor([  656,    58,    15,  ..., 12446,  8656,  3105], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: said ; probability = 51.42%
INFO : Word: , ; probability = 28.83%
INFO : Word: <unk> ; probability = 8.69%
INFO : Word: and ; probability = 3.14%
INFO : Word: which ; probability = 2.22%
INFO : 
-----
Label: the next global is: which
INFO : Label: the next sense is: None
INFO : tensor([   5,   15, 1023,  ..., 1469, 7536, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 36.96%
INFO : Word: <unk> ; probability = 19.9%
INFO : Word: handful ; probability = 16.31%
INFO : Word: evidence ; probability = 14.87%
INFO : Word: which ; probability = 9.51%
INFO : 
-----
Label: the next global is: had
INFO : Label: the next sense is: own.v.01
INFO : tensor([   97,     5,   385,  ..., 12416, 10983,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: was ; probability = 36.89%
INFO : Word: the ; probability = 31.91%
INFO : Word: had ; probability = 26.62%
INFO : Word: of ; probability = 1.88%
INFO : Word: <unk> ; probability = 1.21%
INFO : tensor([11923,  6705,   751,  ...,    90, 16561, 15092], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: own.v.01 ; probability = 98.75%
INFO : Sense: far.r.02 ; probability = 0.96%
INFO : Sense: appoint.v.02 ; probability = 0.08%
INFO : Sense: state.v.01 ; probability = 0.06%
INFO : Sense: group.n.01 ; probability = 0.03%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: overall.s.02
INFO : tensor([   15,    16,    58,  ...,  8960, 12978,  2180], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 87.54%
INFO : Word: by ; probability = 3.59%
INFO : Word: , ; probability = 2.22%
INFO : Word: term ; probability = 1.83%
INFO : Word: of ; probability = 1.39%
INFO : tensor([11902, 16309, 17217,  ...,  7420, 16624, 11068], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: overall.s.02 ; probability = 98.78%
INFO : Sense: state.v.01 ; probability = 0.27%
INFO : Sense: term.n.02 ; probability = 0.24%
INFO : Sense: end.n.02 ; probability = 0.19%
INFO : Sense: late.s.03 ; probability = 0.16%
INFO : 
-----
Label: the next global is: charge
INFO : Label: the next sense is: mission.n.03
INFO : tensor([ 1096,    65,   656,  ...,  2180, 13433, 10452], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: charge ; probability = 71.06%
INFO : Word: of ; probability = 14.67%
INFO : Word: said ; probability = 3.15%
INFO : Word: the ; probability = 2.77%
INFO : Word: <unk> ; probability = 1.95%
INFO : tensor([10875, 16309,  9470,  ..., 11591,  3528, 11068], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: mission.n.03 ; probability = 90.49%
INFO : Sense: state.v.01 ; probability = 5.28%
INFO : Sense: jury.n.01 ; probability = 2.11%
INFO : Sense: end.n.02 ; probability = 0.88%
INFO : Sense: probe.n.01 ; probability = 0.49%
INFO : 
-----
Label: the next global is: of
INFO : Label: the next sense is: None
INFO : tensor([  65,   15,   16,  ..., 9670, 6705, 4732], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: of ; probability = 94.73%
INFO : Word: <unk> ; probability = 2.37%
INFO : Word: by ; probability = 1.14%
INFO : Word: was ; probability = 0.79%
INFO : Word: the ; probability = 0.32%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([    5,    78, 10220,  ..., 11741,  8257,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 31.64%
INFO : Word: such ; probability = 17.18%
INFO : Word: voters ; probability = 16.5%
INFO : Word: possible ; probability = 16.1%
INFO : Word: Atlanta ; probability = 16.06%
INFO : 
-----
Label: the next global is: election
INFO : Label: the next sense is: election.n.01
INFO : tensor([5601,   15, 4203,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: election ; probability = 24.4%
INFO : Word: <unk> ; probability = 23.12%
INFO : Word: widespread ; probability = 9.18%
INFO : Word: number ; probability = 8.96%
INFO : Word: size ; probability = 8.73%
INFO : tensor([ 5926, 15632, 10163,  ..., 17217, 11902,  9704], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: election.n.01 ; probability = 25.62%
INFO : Sense: size.n.01 ; probability = 12.44%
INFO : Sense: location.n.01 ; probability = 11.88%
INFO : Sense: praise.n.01 ; probability = 11.61%
INFO : Sense: manner.n.01 ; probability = 11.57%
INFO : 
-----
Label: the next global is: ,
INFO : Label: the next sense is: None
INFO : tensor([  58,   97,   15,  ..., 5397, 6716, 2115], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: , ; probability = 62.0%
INFO : Word: was ; probability = 27.71%
INFO : Word: <unk> ; probability = 7.23%
INFO : Word: which ; probability = 1.01%
INFO : Word: . ; probability = 0.56%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([    5,    15,  1023,  ..., 11741,  7536,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 35.61%
INFO : Word: <unk> ; probability = 18.63%
INFO : Word: handful ; probability = 16.53%
INFO : Word: evidence ; probability = 16.07%
INFO : Word: which ; probability = 10.54%
INFO : 
-----
Label: the next global is: deserves
INFO : Label: the next sense is: None
INFO : tensor([   15,   128,   348,  ..., 11029,  1023,   430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 19.25%
INFO : Word: that ; probability = 11.36%
INFO : Word: The ; probability = 11.09%
INFO : Word: in ; probability = 6.52%
INFO : Word: considering ; probability = 6.16%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([   5,   60,   25,  ..., 2180, 4203,  569], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 49.57%
INFO : Word: in ; probability = 24.47%
INFO : Word: . ; probability = 16.8%
INFO : Word: to ; probability = 2.61%
INFO : Word: reports ; probability = 2.26%
INFO : 
-----
Label: the next global is: praise
INFO : Label: the next sense is: praise.n.01
INFO : tensor([5601,   15, 4203,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: election ; probability = 24.7%
INFO : Word: <unk> ; probability = 23.24%
INFO : Word: widespread ; probability = 9.07%
INFO : Word: number ; probability = 8.91%
INFO : Word: size ; probability = 8.77%
INFO : tensor([ 5926, 15632, 10424,  ..., 17217, 11902,  9704], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: election.n.01 ; probability = 25.94%
INFO : Sense: size.n.01 ; probability = 12.53%
INFO : Sense: manner.n.01 ; probability = 11.47%
INFO : Sense: location.n.01 ; probability = 11.43%
INFO : Sense: praise.n.01 ; probability = 11.37%
INFO : 
-----
Label: the next global is: and
INFO : Label: the next sense is: None
INFO : tensor([   41,    25,    65,  ...,  2180, 13499,  7587], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: and ; probability = 99.77%
INFO : Word: . ; probability = 0.14%
INFO : Word: of ; probability = 0.03%
INFO : Word: the ; probability = 0.03%
INFO : Word: October ; probability = 0.02%
INFO : 
-----
Label: the next global is: thanks
INFO : Label: the next sense is: thanks.n.01
INFO : tensor([   5, 4465,   97,  ..., 3432, 8912, 4768], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 64.9%
INFO : Word: thanks ; probability = 34.91%
INFO : Word: was ; probability = 0.14%
INFO : Word: and ; probability = 0.03%
INFO : Word: charge ; probability = 0.02%
INFO : tensor([17272, 10875, 13084,  ..., 12026, 10548,  4661], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: thanks.n.01 ; probability = 99.96%
INFO : Sense: mission.n.03 ; probability = 0.03%
INFO : Sense: probe.n.01 ; probability = 0.01%
INFO : Sense: potential.a.01 ; probability = 0.0%
INFO : Sense: such.s.01 ; probability = 0.0%
INFO : 
-----
Label: the next global is: of
INFO : Label: the next sense is: None
INFO : tensor([   65,    41,  2536,  ..., 13170,  8912,  5558], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: of ; probability = 99.81%
INFO : Word: and ; probability = 0.12%
INFO : Word: investigation ; probability = 0.03%
INFO : Word: said ; probability = 0.02%
INFO : Word: <unk> ; probability = 0.01%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([    5, 10220,  3018,  ..., 11741,  8257,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 27.57%
INFO : Word: voters ; probability = 17.89%
INFO : Word: Atlanta ; probability = 17.84%
INFO : Word: such ; probability = 17.63%
INFO : Word: possible ; probability = 16.46%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: location.n.01
INFO : tensor([5601,   15, 4203,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: election ; probability = 24.85%
INFO : Word: <unk> ; probability = 23.15%
INFO : Word: widespread ; probability = 8.96%
INFO : Word: number ; probability = 8.84%
INFO : Word: size ; probability = 8.73%
INFO : tensor([ 5926, 15632, 12858,  ..., 17217, 11902,  9704], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: election.n.01 ; probability = 25.89%
INFO : Sense: size.n.01 ; probability = 12.5%
INFO : Sense: praise.n.01 ; probability = 11.87%
INFO : Sense: manner.n.01 ; probability = 11.28%
INFO : Sense: location.n.01 ; probability = 10.99%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([  15,  656,  385,  ..., 6267, 3105, 8721], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 89.83%
INFO : Word: said ; probability = 3.3%
INFO : Word: had ; probability = 1.07%
INFO : Word: charged ; probability = 0.88%
INFO : Word: of ; probability = 0.85%
INFO : 
-----
Label: the next global is: for
INFO : Label: the next sense is: None
INFO : tensor([   15,   128,   348,  ..., 11029,  1023,   430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 19.57%
INFO : Word: that ; probability = 11.6%
INFO : Word: The ; probability = 11.03%
INFO : Word: in ; probability = 6.5%
INFO : Word: considering ; probability = 6.09%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([    5,    16,    65,  ..., 12092,  2232,  1204], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 99.33%
INFO : Word: by ; probability = 0.65%
INFO : Word: of ; probability = 0.0%
INFO : Word: was ; probability = 0.0%
INFO : Word: investigation ; probability = 0.0%
INFO : 
-----
Label: the next global is: manner
INFO : Label: the next sense is: manner.n.01
INFO : tensor([5601,   15, 4203,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: election ; probability = 24.85%
INFO : Word: <unk> ; probability = 23.15%
INFO : Word: widespread ; probability = 8.96%
INFO : Word: number ; probability = 8.84%
INFO : Word: size ; probability = 8.73%
INFO : tensor([ 5926, 15632, 12858,  ..., 17217, 11902,  9704], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: election.n.01 ; probability = 25.89%
INFO : Sense: size.n.01 ; probability = 12.5%
INFO : Sense: praise.n.01 ; probability = 11.87%
INFO : Sense: manner.n.01 ; probability = 11.28%
INFO : Sense: location.n.01 ; probability = 10.99%
INFO : 
-----
Label: the next global is: in
INFO : Label: the next sense is: None
INFO : tensor([  60,   15,   16,  ..., 4203,  569, 5474], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: in ; probability = 90.52%
INFO : Word: <unk> ; probability = 4.01%
INFO : Word: by ; probability = 3.16%
INFO : Word: a ; probability = 1.55%
INFO : Word: the ; probability = 0.4%
INFO : 
-----
Label: the next global is: which
INFO : Label: the next sense is: None
INFO : tensor([   5, 2280,  285,  ..., 4203,  569, 5474], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 66.26%
INFO : Word: term ; probability = 24.01%
INFO : Word: which ; probability = 9.61%
INFO : Word: in ; probability = 0.03%
INFO : Word: by ; probability = 0.03%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([  385,    97,     5,  ..., 12416, 10983,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: had ; probability = 37.89%
INFO : Word: was ; probability = 29.75%
INFO : Word: the ; probability = 26.83%
INFO : Word: of ; probability = 2.12%
INFO : Word: <unk> ; probability = 1.46%
INFO : 
-----
Label: the next global is: election
INFO : Label: the next sense is: election.n.01
INFO : tensor([5601,   15, 4203,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: election ; probability = 24.24%
INFO : Word: <unk> ; probability = 23.67%
INFO : Word: widespread ; probability = 8.82%
INFO : Word: number ; probability = 8.8%
INFO : Word: size ; probability = 8.74%
INFO : tensor([ 5926, 15632, 12858,  ..., 17217, 11902,  9704], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: election.n.01 ; probability = 25.03%
INFO : Sense: size.n.01 ; probability = 12.37%
INFO : Sense: praise.n.01 ; probability = 12.13%
INFO : Sense: manner.n.01 ; probability = 11.69%
INFO : Sense: location.n.01 ; probability = 11.47%
INFO : 
-----
Label: the next global is: was
INFO : Label: the next sense is: None
INFO : tensor([  58,   97,   15,  ..., 5397, 6716, 2115], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: , ; probability = 70.96%
INFO : Word: was ; probability = 17.86%
INFO : Word: <unk> ; probability = 8.25%
INFO : Word: which ; probability = 0.96%
INFO : Word: . ; probability = 0.54%
INFO : 
-----
Label: the next global is: conducted
INFO : Label: the next sense is: conduct.v.01
INFO : tensor([ 131, 1683, 1726,  ..., 2362, 2688, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: received ; probability = 37.7%
INFO : Word: won ; probability = 34.18%
INFO : Word: conducted ; probability = 26.97%
INFO : Word: further ; probability = 0.28%
INFO : Word: which ; probability = 0.28%
INFO : tensor([18747,  3681, 13771,  ...,  3192, 18384,  2788], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: win.v.01 ; probability = 43.93%
INFO : Sense: conduct.v.01 ; probability = 33.4%
INFO : Sense: receive.v.02 ; probability = 22.08%
INFO : Sense: far.r.02 ; probability = 0.21%
INFO : Sense: handful.n.01 ; probability = 0.14%
INFO : 
-----
Label: the next global is: .
INFO : Label: the next sense is: None
INFO : tensor([   25,   656,    15,  ...,  7587, 13433,  2180], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: . ; probability = 86.18%
INFO : Word: said ; probability = 3.66%
INFO : Word: <unk> ; probability = 3.22%
INFO : Word: the ; probability = 2.49%
INFO : Word: of ; probability = 1.15%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([  15,  131, 1683,  ..., 1397, 7536, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 99.82%
INFO : Word: received ; probability = 0.05%
INFO : Word: won ; probability = 0.04%
INFO : Word: conducted ; probability = 0.03%
INFO : Word: had ; probability = 0.02%
INFO : 
-----
Label: the next global is: The
INFO : Label: the next sense is: None
INFO : tensor([   15,   128,   348,  ..., 11029,  1023,   430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 20.22%
INFO : Word: that ; probability = 11.6%
INFO : Word: The ; probability = 10.86%
INFO : Word: in ; probability = 6.24%
INFO : Word: considering ; probability = 5.99%
INFO : 
-----
Label: the next global is: September
INFO : Label: the next sense is: None
INFO : tensor([8741,   15,  689,  ..., 6334, 4835, 1469], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: jury ; probability = 37.74%
INFO : Word: <unk> ; probability = 36.91%
INFO : Word: September ; probability = 23.87%
INFO : Word: been ; probability = 0.97%
INFO : Word: of ; probability = 0.25%
INFO : 
-----
Label: the next global is: October
INFO : Label: the next sense is: None
INFO : tensor([1469,   41,   58,  ..., 5397, 6677, 2180], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: October ; probability = 91.28%
INFO : Word: and ; probability = 2.84%
INFO : Word: , ; probability = 1.09%
INFO : Word: . ; probability = 1.07%
INFO : Word: to ; probability = 1.0%
INFO : 
-----
Label: the next global is: term
INFO : Label: the next sense is: term.n.02
INFO : tensor([2280,  285, 4835,  ..., 7630, 6716, 2115], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: term ; probability = 88.13%
INFO : Word: which ; probability = 6.36%
INFO : Word: recent ; probability = 1.78%
INFO : Word: to ; probability = 1.62%
INFO : Word: October ; probability = 0.77%
INFO : tensor([17217,  9704, 13109,  ..., 17342,  6432, 14348], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: term.n.02 ; probability = 97.7%
INFO : Sense: late.s.03 ; probability = 1.19%
INFO : Sense: produce.v.04 ; probability = 0.79%
INFO : Sense: overall.s.02 ; probability = 0.27%
INFO : Sense: state.v.01 ; probability = 0.04%
INFO : 
-----
Label: the next global is: jury
INFO : Label: the next sense is: jury.n.01
INFO : tensor([  487,  8741,    15,  ...,  2180,  2483, 13433], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: end ; probability = 53.7%
INFO : Word: jury ; probability = 35.88%
INFO : Word: <unk> ; probability = 5.1%
INFO : Word: the ; probability = 1.68%
INFO : Word: of ; probability = 1.03%
INFO : tensor([ 6038,  9470, 10875,  ..., 16624, 15122, 11068], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: end.n.02 ; probability = 56.67%
INFO : Sense: jury.n.01 ; probability = 40.88%
INFO : Sense: mission.n.03 ; probability = 1.85%
INFO : Sense: late.s.03 ; probability = 0.29%
INFO : Sense: overall.s.02 ; probability = 0.11%
INFO : 
-----
Label: the next global is: had
INFO : Label: the next sense is: None
INFO : tensor([ 1276,   656,   385,  ..., 10983,  9467,  8170], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: further ; probability = 33.71%
INFO : Word: said ; probability = 27.87%
INFO : Word: had ; probability = 27.62%
INFO : Word: <unk> ; probability = 1.72%
INFO : Word: of ; probability = 1.53%
INFO : 
-----
Label: the next global is: been
INFO : Label: the next sense is: None
INFO : tensor([ 422,   15,   65,  ..., 6334, 2541, 1469], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: been ; probability = 92.17%
INFO : Word: <unk> ; probability = 1.68%
INFO : Word: of ; probability = 1.4%
INFO : Word: jury ; probability = 1.01%
INFO : Word: reports ; probability = 0.85%
INFO : 
-----
Label: the next global is: charged
INFO : Label: the next sense is: appoint.v.02
INFO : tensor([ 5474,   656,    15,  ..., 10983,  2688,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: charged ; probability = 96.6%
INFO : Word: said ; probability = 1.15%
INFO : Word: <unk> ; probability = 1.05%
INFO : Word: had ; probability = 0.55%
INFO : Word: further ; probability = 0.39%
INFO : tensor([  751, 12275,  6705,  ...,  2788,  7823, 15092], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: appoint.v.02 ; probability = 97.01%
INFO : Sense: person.n.01 ; probability = 1.21%
INFO : Sense: far.r.02 ; probability = 0.68%
INFO : Sense: state.v.01 ; probability = 0.52%
INFO : Sense: own.v.01 ; probability = 0.21%
INFO : 
-----
Label: the next global is: by
INFO : Label: the next sense is: None
INFO : tensor([   16,    65,  1096,  ...,  2483, 11467, 10452], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: by ; probability = 84.43%
INFO : Word: of ; probability = 5.54%
INFO : Word: charge ; probability = 3.54%
INFO : Word: <unk> ; probability = 2.02%
INFO : Word: the ; probability = 1.89%
INFO : 
-----
Label: the next global is: Fulton
INFO : Label: the next sense is: location.n.01
INFO : tensor([12263,    15,  7536,  ..., 12267, 10986,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: Fulton ; probability = 49.4%
INFO : Word: <unk> ; probability = 48.31%
INFO : Word: relative ; probability = 1.92%
INFO : Word: election ; probability = 0.06%
INFO : Word: investigation ; probability = 0.05%
INFO : tensor([12275, 10163, 14006,  ..., 18995, 18249,  2193], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: person.n.01 ; probability = 66.96%
INFO : Sense: location.n.01 ; probability = 32.16%
INFO : Sense: relative.a.01 ; probability = 0.7%
INFO : Sense: size.n.01 ; probability = 0.05%
INFO : Sense: number.n.02 ; probability = 0.03%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: person.n.01
INFO : tensor([  15,  656,  385,  ..., 6267, 3105, 8721], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 90.46%
INFO : Word: said ; probability = 2.71%
INFO : Word: had ; probability = 1.12%
INFO : Word: further ; probability = 0.89%
INFO : Word: charged ; probability = 0.81%
INFO : tensor([12275, 16309,  6705,  ...,  2193,  2788, 10595], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: person.n.01 ; probability = 94.3%
INFO : Sense: state.v.01 ; probability = 1.7%
INFO : Sense: far.r.02 ; probability = 0.91%
INFO : Sense: location.n.01 ; probability = 0.88%
INFO : Sense: appoint.v.02 ; probability = 0.59%
INFO : 
-----
Label: the next global is: to
INFO : Label: the next sense is: None
INFO : tensor([   54,    25,     5,  ..., 13212,  5397,  2180], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: to ; probability = 44.42%
INFO : Word: . ; probability = 36.56%
INFO : Word: the ; probability = 6.84%
INFO : Word: in ; probability = 4.73%
INFO : Word: term ; probability = 1.97%
INFO : 
-----
Label: the next global is: investigate
INFO : Label: the next sense is: investigate.v.02
INFO : tensor([10298,     5,   285,  ..., 13245,  7536, 12263], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: investigate ; probability = 99.93%
INFO : Word: the ; probability = 0.06%
INFO : Word: which ; probability = 0.01%
INFO : Word: handful ; probability = 0.0%
INFO : Word: evidence ; probability = 0.0%
INFO : tensor([ 9286,  6276,  8201,  ...,  6910, 12329,  2997], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: investigate.v.02 ; probability = 99.96%
INFO : Sense: evidence.n.01 ; probability = 0.03%
INFO : Sense: handful.n.01 ; probability = 0.01%
INFO : Sense: interest.n.01 ; probability = 0.0%
INFO : Sense: potential.a.01 ; probability = 0.0%
INFO : 
-----
Label: the next global is: reports
INFO : Label: the next sense is: report.n.03
INFO : tensor([ 2246,    60,     5,  ...,  6198, 13212, 10452], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: reports ; probability = 87.21%
INFO : Word: in ; probability = 5.58%
INFO : Word: the ; probability = 3.27%
INFO : Word: <unk> ; probability = 1.6%
INFO : Word: been ; probability = 1.31%
INFO : tensor([14129, 16309,  9470,  ...,  3692, 10987, 10228], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: report.n.03 ; probability = 96.75%
INFO : Sense: state.v.01 ; probability = 2.21%
INFO : Sense: jury.n.01 ; probability = 0.31%
INFO : Sense: mission.n.03 ; probability = 0.28%
INFO : Sense: potential.a.01 ; probability = 0.1%
INFO : 
-----
Label: the next global is: of
INFO : Label: the next sense is: None
INFO : tensor([  97,   65,   15,  ..., 9762, 2483, 9670], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: was ; probability = 43.43%
INFO : Word: of ; probability = 32.72%
INFO : Word: <unk> ; probability = 14.25%
INFO : Word: the ; probability = 5.49%
INFO : Word: jury ; probability = 1.68%
INFO : 
-----
Label: the next global is: possible
INFO : Label: the next sense is: potential.a.01
INFO : tensor([    5,  3018, 10220,  ..., 11741,  8257,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 28.91%
INFO : Word: Atlanta ; probability = 18.3%
INFO : Word: voters ; probability = 18.2%
INFO : Word: such ; probability = 16.53%
INFO : Word: possible ; probability = 14.96%
INFO : tensor([16762, 12835,  6276,  ..., 11433,  8472,  1387], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: such.s.01 ; probability = 56.0%
INFO : Sense: potential.a.01 ; probability = 42.14%
INFO : Sense: evidence.n.01 ; probability = 0.91%
INFO : Sense: handful.n.01 ; probability = 0.65%
INFO : Sense: report.n.03 ; probability = 0.18%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([   15,     5,  2246,  ...,  4835, 10983,  1469], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 96.19%
INFO : Word: the ; probability = 2.26%
INFO : Word: reports ; probability = 0.91%
INFO : Word: of ; probability = 0.33%
INFO : Word: was ; probability = 0.27%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([   15,   128,   348,  ..., 11029,  1023,   430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 18.46%
INFO : Word: that ; probability = 12.09%
INFO : Word: The ; probability = 11.9%
INFO : Word: in ; probability = 6.03%
INFO : Word: no ; probability = 6.03%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([  15,  348,  128,  ..., 7229, 1023,  430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 19.98%
INFO : Word: The ; probability = 12.1%
INFO : Word: that ; probability = 11.95%
INFO : Word: for ; probability = 6.03%
INFO : Word: no ; probability = 5.89%
INFO : 
-----
Label: the next global is: in
INFO : Label: the next sense is: None
INFO : tensor([  15,  348,  128,  ..., 7229, 1023,  430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 19.98%
INFO : Word: The ; probability = 12.1%
INFO : Word: that ; probability = 11.95%
INFO : Word: for ; probability = 6.03%
INFO : Word: no ; probability = 5.89%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([2280,  285,    5,  ..., 4203,  569, 5474], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: term ; probability = 42.95%
INFO : Word: which ; probability = 29.16%
INFO : Word: the ; probability = 27.76%
INFO : Word: <unk> ; probability = 0.05%
INFO : Word: in ; probability = 0.03%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([5601,   15, 3209,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: election ; probability = 25.58%
INFO : Word: <unk> ; probability = 22.23%
INFO : Word: manner ; probability = 8.87%
INFO : Word: size ; probability = 8.65%
INFO : Word: praise ; probability = 8.65%
INFO : 
-----
Label: the next global is: primary
INFO : Label: the next sense is: primary.n.01
INFO : tensor([  15,  348,  128,  ..., 7229, 1023,  430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 19.98%
INFO : Word: The ; probability = 12.1%
INFO : Word: that ; probability = 11.95%
INFO : Word: for ; probability = 6.03%
INFO : Word: no ; probability = 5.89%
INFO : tensor([ 3056, 13019,  8227,  ...,  1134,  8201,  6276], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: city.n.01 ; probability = 27.4%
INFO : Sense: primary.n.01 ; probability = 23.2%
INFO : Sense: happen.v.01 ; probability = 17.89%
INFO : Sense: merely.r.01 ; probability = 17.18%
INFO : Sense: consider.v.04 ; probability = 13.72%
INFO : 
-----
Label: the next global is: which
INFO : Label: the next sense is: None
INFO : tensor([ 548,  285,   58,  ..., 3105, 8656, 5397], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: produced ; probability = 55.52%
INFO : Word: which ; probability = 30.63%
INFO : Word: , ; probability = 3.94%
INFO : Word: and ; probability = 2.73%
INFO : Word: <unk> ; probability = 2.31%
INFO : 
-----
Label: the next global is: was
INFO : Label: the next sense is: None
INFO : tensor([  385,     5,    97,  ..., 12416, 10983,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: had ; probability = 42.16%
INFO : Word: the ; probability = 27.1%
INFO : Word: was ; probability = 25.05%
INFO : Word: of ; probability = 2.32%
INFO : Word: <unk> ; probability = 1.43%
INFO : 
-----
Label: the next global is: won
INFO : Label: the next sense is: win.v.01
INFO : tensor([1726,  131, 1683,  ..., 2362, 2688, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: conducted ; probability = 35.58%
INFO : Word: received ; probability = 33.74%
INFO : Word: won ; probability = 29.49%
INFO : Word: which ; probability = 0.31%
INFO : Word: further ; probability = 0.28%
INFO : tensor([ 3681, 18747, 13771,  ...,  3192, 18384,  2788], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: conduct.v.01 ; probability = 43.86%
INFO : Sense: win.v.01 ; probability = 36.03%
INFO : Sense: receive.v.02 ; probability = 19.5%
INFO : Sense: far.r.02 ; probability = 0.22%
INFO : Sense: handful.n.01 ; probability = 0.13%
INFO : 
-----
Label: the next global is: by
INFO : Label: the next sense is: None
INFO : tensor([  16,   15,    5,  ..., 9670, 2483, 5474], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: by ; probability = 91.89%
INFO : Word: <unk> ; probability = 4.35%
INFO : Word: the ; probability = 1.75%
INFO : Word: in ; probability = 0.61%
INFO : Word: term ; probability = 0.34%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: person.n.01
INFO : tensor([12263,    15,  7536,  ..., 12267, 10986,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: Fulton ; probability = 56.4%
INFO : Word: <unk> ; probability = 41.36%
INFO : Word: relative ; probability = 1.87%
INFO : Word: election ; probability = 0.06%
INFO : Word: investigation ; probability = 0.05%
INFO : tensor([12275, 10163, 14006,  ..., 18995, 18249,  2193], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: person.n.01 ; probability = 52.23%
INFO : Sense: location.n.01 ; probability = 46.74%
INFO : Sense: relative.a.01 ; probability = 0.81%
INFO : Sense: size.n.01 ; probability = 0.06%
INFO : Sense: number.n.02 ; probability = 0.04%
INFO : 
-----
Label: the next global is: .
INFO : Label: the next sense is: None
INFO : tensor([   54,    25,     5,  ..., 13212,  5397,  2180], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: to ; probability = 51.27%
INFO : Word: . ; probability = 29.76%
INFO : Word: the ; probability = 6.97%
INFO : Word: in ; probability = 4.65%
INFO : Word: term ; probability = 1.91%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([  15, 1726,  131,  ..., 1397, 7536, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 99.84%
INFO : Word: conducted ; probability = 0.04%
INFO : Word: received ; probability = 0.04%
INFO : Word: won ; probability = 0.03%
INFO : Word: had ; probability = 0.02%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([  15,  348,  128,  ..., 7229, 1023,  430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 21.41%
INFO : Word: The ; probability = 11.98%
INFO : Word: that ; probability = 11.75%
INFO : Word: for ; probability = 6.01%
INFO : Word: in ; probability = 5.9%
INFO : 
-----
Label: the next global is: Only
INFO : Label: the next sense is: merely.r.01
INFO : tensor([  15,  348,  128,  ..., 7229, 1023,  430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 21.41%
INFO : Word: The ; probability = 11.98%
INFO : Word: that ; probability = 11.75%
INFO : Word: for ; probability = 6.01%
INFO : Word: in ; probability = 5.9%
INFO : tensor([ 3056, 13019,  8227,  ...,  1134,  8201,  6276], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: city.n.01 ; probability = 27.04%
INFO : Sense: primary.n.01 ; probability = 24.87%
INFO : Sense: happen.v.01 ; probability = 17.71%
INFO : Sense: merely.r.01 ; probability = 16.3%
INFO : Sense: consider.v.04 ; probability = 13.48%
INFO : 
-----
Label: the next global is: a
INFO : Label: the next sense is: None
INFO : tensor([  17,   60,  422,  ..., 5474, 4203,  569], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: a ; probability = 97.43%
INFO : Word: in ; probability = 0.92%
INFO : Word: been ; probability = 0.77%
INFO : Word: the ; probability = 0.45%
INFO : Word: by ; probability = 0.24%
INFO : 
-----
Label: the next global is: relative
INFO : Label: the next sense is: relative.a.01
INFO : tensor([ 7536,    15,    16,  ..., 10639,  3361,  6847], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: relative ; probability = 96.14%
INFO : Word: <unk> ; probability = 3.39%
INFO : Word: by ; probability = 0.25%
INFO : Word: Fulton ; probability = 0.16%
INFO : Word: investigation ; probability = 0.03%
INFO : tensor([14006, 10163, 12275,  ...,  4086,  7913,  4536], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: relative.a.01 ; probability = 98.25%
INFO : Sense: location.n.01 ; probability = 0.77%
INFO : Sense: person.n.01 ; probability = 0.73%
INFO : Sense: probe.n.01 ; probability = 0.16%
INFO : Sense: jury.n.01 ; probability = 0.05%
INFO : Global step=1596	 ; Iteration time=0.72077
INFO : 
-----
Label: the next global is: handful
INFO : Label: the next sense is: handful.n.01
INFO : tensor([  15,    5,  430,  ..., 1469, 7536, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 31.79%
INFO : Word: the ; probability = 23.29%
INFO : Word: evidence ; probability = 15.5%
INFO : Word: which ; probability = 14.83%
INFO : Word: handful ; probability = 12.57%
INFO : tensor([ 6276,  8201, 12835,  ...,  7088,  5070,  1387], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: evidence.n.01 ; probability = 55.87%
INFO : Sense: handful.n.01 ; probability = 42.14%
INFO : Sense: potential.a.01 ; probability = 0.91%
INFO : Sense: such.s.01 ; probability = 0.75%
INFO : Sense: conduct.v.01 ; probability = 0.13%
INFO : 
-----
Label: the next global is: of
INFO : Label: the next sense is: None
INFO : tensor([   65,    15,   285,  ..., 13619,  2232,  5253], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: of ; probability = 98.75%
INFO : Word: <unk> ; probability = 0.86%
INFO : Word: which ; probability = 0.23%
INFO : Word: the ; probability = 0.11%
INFO : Word: said ; probability = 0.02%
INFO : 
-----
Label: the next global is: such
INFO : Label: the next sense is: such.s.01
INFO : tensor([    5,   846,  3018,  ..., 11741,  8257,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 28.54%
INFO : Word: possible ; probability = 18.24%
INFO : Word: Atlanta ; probability = 17.58%
INFO : Word: voters ; probability = 17.2%
INFO : Word: such ; probability = 14.64%
INFO : tensor([12835, 16762,  6276,  ..., 11433,  8472,  1387], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: potential.a.01 ; probability = 52.94%
INFO : Sense: such.s.01 ; probability = 45.0%
INFO : Sense: evidence.n.01 ; probability = 1.04%
INFO : Sense: handful.n.01 ; probability = 0.7%
INFO : Sense: report.n.03 ; probability = 0.19%
INFO : 
-----
Label: the next global is: reports
INFO : Label: the next sense is: report.n.03
INFO : tensor([ 2246,    16,     5,  ..., 10452,  1204, 11157], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: reports ; probability = 100.0%
INFO : Word: by ; probability = 0.0%
INFO : Word: the ; probability = 0.0%
INFO : Word: a ; probability = 0.0%
INFO : Word: of ; probability = 0.0%
INFO : tensor([14129, 11902, 16309,  ...,  5948, 17814,  7913], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: report.n.03 ; probability = 99.99%
INFO : Sense: overall.s.02 ; probability = 0.01%
INFO : Sense: state.v.01 ; probability = 0.0%
INFO : Sense: relative.a.01 ; probability = 0.0%
INFO : Sense: probe.n.01 ; probability = 0.0%
INFO : 
-----
Label: the next global is: was
INFO : Label: the next sense is: None
INFO : tensor([  65,   97,   15,  ..., 2483, 9762, 9670], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: of ; probability = 49.25%
INFO : Word: was ; probability = 27.06%
INFO : Word: <unk> ; probability = 17.1%
INFO : Word: the ; probability = 3.37%
INFO : Word: jury ; probability = 1.49%
INFO : 
-----
Label: the next global is: received
INFO : Label: the next sense is: receive.v.02
INFO : tensor([1726, 1683,  131,  ..., 2362, 2688, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: conducted ; probability = 36.54%
INFO : Word: won ; probability = 33.49%
INFO : Word: received ; probability = 28.78%
INFO : Word: which ; probability = 0.33%
INFO : Word: further ; probability = 0.25%
INFO : tensor([ 3681, 18747, 13771,  ...,  3192, 18384,  2788], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: conduct.v.01 ; probability = 43.42%
INFO : Sense: win.v.01 ; probability = 39.73%
INFO : Sense: receive.v.02 ; probability = 16.26%
INFO : Sense: far.r.02 ; probability = 0.21%
INFO : Sense: handful.n.01 ; probability = 0.13%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([  15,   65,   97,  ..., 2180, 2483, 9670], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 60.07%
INFO : Word: of ; probability = 20.78%
INFO : Word: was ; probability = 7.58%
INFO : Word: the ; probability = 7.01%
INFO : Word: by ; probability = 1.58%
INFO : 
-----
Label: the next global is: ,
INFO : Label: the next sense is: None
INFO : tensor([  15,  348,  128,  ..., 7229, 1023,  430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 24.26%
INFO : Word: The ; probability = 11.55%
INFO : Word: that ; probability = 11.18%
INFO : Word: for ; probability = 5.86%
INFO : Word: in ; probability = 5.73%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([  15,    5,  430,  ..., 1469, 7536, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 33.36%
INFO : Word: the ; probability = 20.69%
INFO : Word: evidence ; probability = 14.99%
INFO : Word: which ; probability = 14.94%
INFO : Word: handful ; probability = 14.06%
INFO : 
-----
Label: the next global is: jury
INFO : Label: the next sense is: jury.n.01
INFO : tensor([  15, 5601, 3209,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 26.99%
INFO : Word: election ; probability = 24.51%
INFO : Word: manner ; probability = 8.4%
INFO : Word: praise ; probability = 8.32%
INFO : Word: number ; probability = 7.97%
INFO : tensor([ 5926, 10163, 10424,  ..., 17217, 11902,  9704], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: election.n.01 ; probability = 26.18%
INFO : Sense: location.n.01 ; probability = 12.73%
INFO : Sense: manner.n.01 ; probability = 12.51%
INFO : Sense: praise.n.01 ; probability = 12.36%
INFO : Sense: size.n.01 ; probability = 11.3%
INFO : 
-----
Label: the next global is: said
INFO : Label: the next sense is: state.v.01
INFO : tensor([  385,  1276,   656,  ..., 10983,  9467,  8170], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: had ; probability = 35.59%
INFO : Word: further ; probability = 32.36%
INFO : Word: said ; probability = 19.23%
INFO : Word: <unk> ; probability = 2.63%
INFO : Word: of ; probability = 1.99%
INFO : tensor([ 6705, 16309, 12275,  ...,  7322,  2788, 15092], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: far.r.02 ; probability = 64.34%
INFO : Sense: state.v.01 ; probability = 29.48%
INFO : Sense: person.n.01 ; probability = 1.54%
INFO : Sense: mission.n.03 ; probability = 1.33%
INFO : Sense: appoint.v.02 ; probability = 0.61%
INFO : 
-----
Label: the next global is: ,
INFO : Label: the next sense is: None
INFO : tensor([   60, 11525,    58,  ...,  1683,  4203,   569], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: in ; probability = 43.21%
INFO : Word: Friday ; probability = 33.06%
INFO : Word: , ; probability = 22.9%
INFO : Word: . ; probability = 0.39%
INFO : Word: was ; probability = 0.19%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([  15,    5,  430,  ..., 1469, 7536, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 33.36%
INFO : Word: the ; probability = 20.69%
INFO : Word: evidence ; probability = 14.99%
INFO : Word: which ; probability = 14.94%
INFO : Word: handful ; probability = 14.06%
INFO : 
-----
Label: the next global is: considering
INFO : Label: the next sense is: consider.v.04
INFO : tensor([  15,  348,  128,  ..., 7229, 1023,  430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 26.42%
INFO : Word: The ; probability = 11.13%
INFO : Word: that ; probability = 10.66%
INFO : Word: for ; probability = 5.74%
INFO : Word: in ; probability = 5.59%
INFO : tensor([13019,  3056, 10720,  ...,  1134,  8201,  6276], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: primary.n.01 ; probability = 26.7%
INFO : Sense: city.n.01 ; probability = 25.82%
INFO : Sense: merely.r.01 ; probability = 17.34%
INFO : Sense: happen.v.01 ; probability = 16.92%
INFO : Sense: consider.v.04 ; probability = 12.65%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([   5,   15,   65,  ..., 9670, 2483, 2180], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 38.25%
INFO : Word: <unk> ; probability = 18.65%
INFO : Word: of ; probability = 17.61%
INFO : Word: . ; probability = 7.06%
INFO : Word: end ; probability = 5.0%
INFO : 
-----
Label: the next global is: widespread
INFO : Label: the next sense is: widespread.s.01
INFO : tensor([  15, 5601, 3209,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 26.99%
INFO : Word: election ; probability = 24.51%
INFO : Word: manner ; probability = 8.4%
INFO : Word: praise ; probability = 8.32%
INFO : Word: number ; probability = 7.97%
INFO : tensor([ 5926, 10163, 10424,  ..., 17217, 11902,  9704], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: election.n.01 ; probability = 26.18%
INFO : Sense: location.n.01 ; probability = 12.73%
INFO : Sense: manner.n.01 ; probability = 12.51%
INFO : Sense: praise.n.01 ; probability = 12.36%
INFO : Sense: size.n.01 ; probability = 11.3%
INFO : 
-----
Label: the next global is: interest
INFO : Label: the next sense is: interest.n.01
INFO : tensor([ 3371,     5,   656,  ..., 10392,  1362, 12180], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: interest ; probability = 99.95%
INFO : Word: the ; probability = 0.03%
INFO : Word: said ; probability = 0.01%
INFO : Word: . ; probability = 0.01%
INFO : Word: of ; probability = 0.0%
INFO : tensor([ 9203, 16309,  6705,  ...,  7785,  8421,  6004], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: interest.n.01 ; probability = 99.95%
INFO : Sense: state.v.01 ; probability = 0.05%
INFO : Sense: far.r.02 ; probability = 0.0%
INFO : Sense: mission.n.03 ; probability = 0.0%
INFO : Sense: report.n.03 ; probability = 0.0%
INFO : 
-----
Label: the next global is: in
INFO : Label: the next sense is: None
INFO : tensor([   60,     5,    25,  ..., 13212, 10983,  2180], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: in ; probability = 40.18%
INFO : Word: the ; probability = 29.14%
INFO : Word: . ; probability = 7.55%
INFO : Word: reports ; probability = 5.56%
INFO : Word: to ; probability = 3.71%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([ 285, 2280,    5,  ..., 4203,  569, 5474], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: which ; probability = 43.82%
INFO : Word: term ; probability = 28.05%
INFO : Word: the ; probability = 27.93%
INFO : Word: <unk> ; probability = 0.12%
INFO : Word: in ; probability = 0.02%
INFO : 
-----
Label: the next global is: election
INFO : Label: the next sense is: election.n.01
INFO : tensor([  15, 5601, 3209,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 27.53%
INFO : Word: election ; probability = 23.95%
INFO : Word: manner ; probability = 8.34%
INFO : Word: praise ; probability = 8.28%
INFO : Word: jury ; probability = 8.0%
INFO : tensor([ 5926, 10424, 10163,  ..., 17217, 11902,  9704], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: election.n.01 ; probability = 26.11%
INFO : Sense: manner.n.01 ; probability = 12.62%
INFO : Sense: location.n.01 ; probability = 12.52%
INFO : Sense: praise.n.01 ; probability = 12.3%
INFO : Sense: size.n.01 ; probability = 11.05%
INFO : 
-----
Label: the next global is: ,
INFO : Label: the next sense is: None
INFO : tensor([  58,   97,   15,  ..., 5397, 6716, 2115], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: , ; probability = 53.95%
INFO : Word: was ; probability = 27.45%
INFO : Word: <unk> ; probability = 15.41%
INFO : Word: which ; probability = 1.49%
INFO : Word: . ; probability = 0.42%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([  15,    5,  285,  ..., 1469, 7536, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 35.22%
INFO : Word: the ; probability = 19.98%
INFO : Word: which ; probability = 14.9%
INFO : Word: handful ; probability = 14.45%
INFO : Word: evidence ; probability = 13.65%
INFO : 
-----
Label: the next global is: number
INFO : Label: the next sense is: number.n.02
INFO : tensor([  15, 5601, 3209,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 27.53%
INFO : Word: election ; probability = 23.95%
INFO : Word: manner ; probability = 8.34%
INFO : Word: praise ; probability = 8.28%
INFO : Word: jury ; probability = 8.0%
INFO : tensor([ 5926, 10424, 10163,  ..., 17217, 11902,  9704], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: election.n.01 ; probability = 26.11%
INFO : Sense: manner.n.01 ; probability = 12.62%
INFO : Sense: location.n.01 ; probability = 12.52%
INFO : Sense: praise.n.01 ; probability = 12.3%
INFO : Sense: size.n.01 ; probability = 11.05%
INFO : 
-----
Label: the next global is: of
INFO : Label: the next sense is: None
INFO : tensor([   65,  1096,    15,  ..., 10452,  6705,  2180], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: of ; probability = 76.71%
INFO : Word: charge ; probability = 8.71%
INFO : Word: <unk> ; probability = 4.18%
INFO : Word: was ; probability = 3.19%
INFO : Word: by ; probability = 1.98%
INFO : 
-----
Label: the next global is: voters
INFO : Label: the next sense is: None
INFO : tensor([    5,   846,    78,  ..., 11741,  8257,  4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: the ; probability = 29.66%
INFO : Word: possible ; probability = 19.34%
INFO : Word: such ; probability = 17.2%
INFO : Word: Atlanta ; probability = 15.3%
INFO : Word: voters ; probability = 14.69%
INFO : 
-----
Label: the next global is: and
INFO : Label: the next sense is: None
INFO : tensor([  41,   58,   15,  ..., 1647, 8656, 3105], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: and ; probability = 84.9%
INFO : Word: , ; probability = 6.9%
INFO : Word: <unk> ; probability = 2.8%
INFO : Word: October ; probability = 1.51%
INFO : Word: produced ; probability = 1.32%
INFO : 
-----
Label: the next global is: the
INFO : Label: the next sense is: None
INFO : tensor([4465,    5,   97,  ..., 8912,  131, 4768], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: thanks ; probability = 69.84%
INFO : Word: the ; probability = 29.96%
INFO : Word: was ; probability = 0.13%
INFO : Word: and ; probability = 0.03%
INFO : Word: charge ; probability = 0.02%
INFO : 
-----
Label: the next global is: size
INFO : Label: the next sense is: size.n.01
INFO : tensor([  15, 5601, 3209,  ...,   54, 1469, 4835], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 26.53%
INFO : Word: election ; probability = 24.33%
INFO : Word: manner ; probability = 8.41%
INFO : Word: jury ; probability = 8.32%
INFO : Word: praise ; probability = 8.3%
INFO : tensor([ 5926, 10424, 10163,  ..., 17217, 11902,  9704], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: election.n.01 ; probability = 26.32%
INFO : Sense: manner.n.01 ; probability = 12.57%
INFO : Sense: location.n.01 ; probability = 12.23%
INFO : Sense: praise.n.01 ; probability = 12.19%
INFO : Sense: size.n.01 ; probability = 10.7%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([   15,    58,    97,  ..., 10194,  3105, 13433], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 71.23%
INFO : Word: , ; probability = 6.45%
INFO : Word: was ; probability = 5.42%
INFO : Word: . ; probability = 4.94%
INFO : Word: recent ; probability = 2.18%
INFO : 
-----
Label: the next global is: city
INFO : Label: the next sense is: city.n.01
INFO : tensor([  15,  348,  128,  ..., 7229, 1023,  430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 27.56%
INFO : Word: The ; probability = 10.57%
INFO : Word: that ; probability = 10.03%
INFO : Word: primary ; probability = 5.6%
INFO : Word: for ; probability = 5.57%
INFO : tensor([13019,  3056, 10720,  ...,  1134,  8201,  6276], device='cuda:0')
INFO : The top- 5 predicted senses are:
INFO : Sense: primary.n.01 ; probability = 27.6%
INFO : Sense: city.n.01 ; probability = 23.85%
INFO : Sense: merely.r.01 ; probability = 18.05%
INFO : Sense: happen.v.01 ; probability = 16.32%
INFO : Sense: consider.v.04 ; probability = 13.58%
INFO : 
-----
Label: the next global is: <unk>
INFO : Label: the next sense is: None
INFO : tensor([  15,   58, 8741,  ...,  605, 4027, 4653], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 99.96%
INFO : Word: , ; probability = 0.01%
INFO : Word: jury ; probability = 0.01%
INFO : Word: said ; probability = 0.01%
INFO : Word: of ; probability = 0.01%
INFO : 
-----
Label: the next global is: .
INFO : Label: the next sense is: None
INFO : tensor([  15,  348,  128,  ..., 7229, 1023,  430], device='cuda:0')
INFO : The top- 5 predicted globals are:
INFO : Word: <unk> ; probability = 27.56%
INFO : Word: The ; probability = 10.57%
INFO : Word: that ; probability = 10.03%
INFO : Word: primary ; probability = 5.6%
INFO : Word: for ; probability = 5.57%
INFO : -----
 End of epoch. Global step n.1600, using batch_size=8
INFO : Training, epoch nll_loss= 2.20181
------
